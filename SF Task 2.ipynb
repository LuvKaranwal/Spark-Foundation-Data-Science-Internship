{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Foundation \n",
    "\n",
    "## Task 2 :) Prediction of scores of a student based on the no, of hours he/she invested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "os.chdir(\"C:\\\\Users\\\\Love Karnval\\\\Desktop\\\\sparks foundation internship\\\\task 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 1) (25,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hours</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.5</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.1</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.2</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.5</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.2</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.5</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.3</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.7</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hours  Scores\n",
       "0    2.5      21\n",
       "1    5.1      47\n",
       "2    3.2      27\n",
       "3    8.5      75\n",
       "4    3.5      30\n",
       "5    1.5      20\n",
       "6    9.2      88\n",
       "7    5.5      60\n",
       "8    8.3      81\n",
       "9    2.7      25"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv(\"student_time_spent - student_scores.csv\")\n",
    "data_values = dataframe.values\n",
    "X, y = data_values[:, :-1], data_values[:, -1]\n",
    "# summarize the shape of the dataset\n",
    "print(X.shape, y.shape)\n",
    "dataframe.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis between the two variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x233f9ac1188>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ### Correlation Analysis : Only for continuous numeric variables.\n",
    "#   # Correlation plot.NOTE:cp is only for continuous numeric variables.\n",
    "#   # Extreme Blue:highly positively correlated.\n",
    "#   # Extreme Red :highly negatively correlated.\n",
    "colnames=['Hours', 'Scores']\n",
    "df_corr = dataframe.loc[:,colnames]\n",
    "# print(df_corr.shape)\n",
    "\n",
    "corr_mat=dataframe.corr(method='pearson')\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(corr_mat,vmax=1,square=True,annot=True,cmap='cubehelix')\n",
    "\n",
    "# brp = brp.drop(['workingday','atemp'],axis=1)\n",
    "# print(brp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data into train and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 1) (3, 1) (22,) (3,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.12, random_state=47)\n",
    "# summarize the shape of the train and test sets\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1). Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE For Linear Regression: 4.35\n",
      "Predicted Score 92.39\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE For Linear Regression: %.2f' % mae)\n",
    "\n",
    "test = np.array([[9.25]])\n",
    "y = model.predict(test)\n",
    "print('Predicted Score',round(y[0],2))\n",
    "\n",
    "final_table = pd.DataFrame(columns=['Model Name','Mae Score', 'Predicted Score for 9.25 hrs'])\n",
    "\n",
    "a=0\n",
    "final_table.loc[a] = ['Linear Regression Model'] + [round(mae,2)] + [round(y[0],2)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2). Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE For Random Forest Regression: 2.477\n",
      "Predicted Score 88.9\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE For Random Forest Regression: %.3f' % mae)\n",
    "\n",
    "test = np.array([[9.25]])\n",
    "y = model.predict(test)\n",
    "print('Predicted Score',round(y[0],2))\n",
    "\n",
    "a+=1\n",
    "final_table.loc[a] = ['Random Forest Regression'] + [round(mae,2)] + [round(y[0],2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3). Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE For Decision Tree Regression: 5.000\n",
      "Predicted Score 88.0\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE For Decision Tree Regression: %.3f' % mae)\n",
    "\n",
    "test = np.array([[9.25]])\n",
    "y = model.predict(test)\n",
    "print('Predicted Score',round(y[0],2))\n",
    "\n",
    "a+=1\n",
    "final_table.loc[a] = ['Decision Tree Regression'] + [round(mae,2)] + [round(y[0],2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4). GB Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE For Support Vector Regression: 4.871\n",
      "Predicted Score 88.08\n"
     ]
    }
   ],
   "source": [
    "model =  GradientBoostingRegressor(random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE For Support Vector Regression: %.3f' % mae)\n",
    "\n",
    "test = np.array([[9.25]])\n",
    "y = model.predict(test)\n",
    "print('Predicted Score',round(y[0],2))\n",
    "\n",
    "a+=1\n",
    "final_table.loc[a] = ['GB Regression Model'] + [round(mae,2)] + [round(y[0],2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5). XGB Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE For XGB Model: 4.927\n",
      "Predicted Score 85.34\n"
     ]
    }
   ],
   "source": [
    "model = regressor = xgb.XGBRegressor(\n",
    "    n_estimators=12,\n",
    "    reg_lambda=1,\n",
    "    gamma=0,\n",
    "    max_depth=3\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE For XGB Model: %.3f' % mae)\n",
    "\n",
    "test = np.array([[9.25]])\n",
    "y = model.predict(test)\n",
    "print('Predicted Score',round(y[0],2))\n",
    "\n",
    "a+=1\n",
    "final_table.loc[a] = ['XGB Regression Model'] + [round(mae,2)] + [round(y[0],2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6). Bayesian Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE For Bayesian Ridge Regression: 4.358\n",
      "Predicted Score 92.29\n"
     ]
    }
   ],
   "source": [
    "model = BayesianRidge()\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE For Bayesian Ridge Regression: %.3f' % mae)\n",
    "\n",
    "test = np.array([[9.25]])\n",
    "y = model.predict(test)\n",
    "print('Predicted Score',round(y[0],2))\n",
    "\n",
    "a+=1\n",
    "final_table.loc[a] = ['Bayesian Ridge Regression'] + [round(mae,2)] + [round(y[0],2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7). Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE For Support Vector Regression: 20.930\n",
      "Predicted Score 58.7\n"
     ]
    }
   ],
   "source": [
    "model =  SVR(C=1.0, epsilon=0.2)\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE For Support Vector Regression: %.3f' % mae)\n",
    "\n",
    "test = np.array([[9.25]])\n",
    "y = model.predict(test)\n",
    "print('Predicted Score',round(y[0],2))\n",
    "\n",
    "a+=1\n",
    "final_table.loc[a] = ['Support Vector Regression'] + [round(mae,2)] + [round(y[0],2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8). KNN Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE For Support Vector Regression: 0.667\n",
      "Predicted Score 91.5\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsRegressor(n_neighbors = 2)\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE For Support Vector Regression: %.3f' % mae)\n",
    "\n",
    "test = np.array([[9.25]])\n",
    "y = model.predict(test)\n",
    "print('Predicted Score',round(y[0],2))\n",
    "\n",
    "a+=1\n",
    "final_table.loc[a] = ['KNN Regression'] + [round(mae,2)] + [round(y[0],2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the Final dataframe of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Mae Score</th>\n",
       "      <th>Predicted Score for 9.25 hrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN Regression</td>\n",
       "      <td>0.67</td>\n",
       "      <td>91.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Regression</td>\n",
       "      <td>2.48</td>\n",
       "      <td>88.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression Model</td>\n",
       "      <td>4.35</td>\n",
       "      <td>92.390000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bayesian Ridge Regression</td>\n",
       "      <td>4.36</td>\n",
       "      <td>92.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GB Regression Model</td>\n",
       "      <td>4.87</td>\n",
       "      <td>88.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGB Regression Model</td>\n",
       "      <td>4.93</td>\n",
       "      <td>85.339996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree Regression</td>\n",
       "      <td>5.00</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Support Vector Regression</td>\n",
       "      <td>20.93</td>\n",
       "      <td>58.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model Name  Mae Score  Predicted Score for 9.25 hrs\n",
       "7             KNN Regression       0.67                     91.500000\n",
       "1   Random Forest Regression       2.48                     88.900000\n",
       "0    Linear Regression Model       4.35                     92.390000\n",
       "5  Bayesian Ridge Regression       4.36                     92.290000\n",
       "3        GB Regression Model       4.87                     88.080000\n",
       "4       XGB Regression Model       4.93                     85.339996\n",
       "2   Decision Tree Regression       5.00                     88.000000\n",
       "6  Support Vector Regression      20.93                     58.700000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_table.sort_values(\"Mae Score\", axis = 0, ascending = True, \n",
    "                 inplace = True, na_position ='last') \n",
    "final_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for deciding the optimum test size to predict the most efficient scores by comparing the mae scores of most efficient models in that test size \"x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom math import sqrt\\nff_table = pd.DataFrame(columns=[\\'test size\\',\\'mae score\\',\\'model name\\'])\\nfff_table = pd.DataFrame(columns=[\\'random state\\', \\'test size\\',\\'mae score\\',\\'model name\\'])\\nb=0\\nx=0.10\\nrs= 1\\nq=0\\nwhile rs <=50:\\n    x=0.10\\n    while x <= 0.66:\\n        dataframe = pd.read_csv(\"student_time_spent - student_scores.csv\")\\n        data_values = dataframe.values\\n        X, y = data_values[:, :-1], data_values[:, -1]\\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=round(x,2), random_state=rs)\\n        model = LinearRegression()\\n        model.fit(X_train, y_train) \\n        yhat = model.predict(X_test)\\n        mae = mean_absolute_error(y_test, yhat)\\n        test = np.array([[9.25]])\\n        y = model.predict(test)\\n        final_table = pd.DataFrame(columns=[\\'Model Name\\',\\'Mae Score\\', \\'Predicted Score for 9.25 hrs\\'])\\n        a=0\\n        final_table.loc[a] = [\\'Linear Regression Model\\'] + [round(mae,2)] + [round(y[0],2)]\\n\\n        model = RandomForestRegressor(random_state=1, n_estimators=32)\\n        model.fit(X_train, y_train)\\n        yhat = model.predict(X_test)\\n        mae = mean_absolute_error(y_test, yhat)\\n        y = model.predict(test)\\n        a+=1\\n        final_table.loc[a] = [\\'Random Forest Regression\\'] + [round(mae,2)] + [round(y[0],2)]\\n\\n        model = DecisionTreeRegressor(random_state=1)\\n        model.fit(X_train, y_train)\\n        yhat = model.predict(X_test)\\n        mae = mean_absolute_error(y_test, yhat)\\n        y = model.predict(test)\\n        a+=1\\n        final_table.loc[a] = [\\'Decision Tree Regression\\'] + [round(mae,2)] + [round(y[0],2)]\\n\\n        model =  GradientBoostingRegressor(random_state=1)\\n        model.fit(X_train, y_train)\\n        yhat = model.predict(X_test)\\n        mae = mean_absolute_error(y_test, yhat)\\n        y = model.predict(test)\\n        a+=1\\n        final_table.loc[a] = [\\'GB Regression Model\\'] + [round(mae,2)] + [round(y[0],2)]\\n\\n        model = regressor = xgb.XGBRegressor(\\n        n_estimators=100,\\n        reg_lambda=1,\\n        gamma=0,\\n        max_depth=4\\n        )\\n        model.fit(X_train, y_train)\\n        yhat = model.predict(X_test)\\n        mae = mean_absolute_error(y_test, yhat)\\n        y = model.predict(test)\\n        a+=1\\n        final_table.loc[a] = [\\'XGB Regression Model\\'] + [round(mae,2)] + [round(y[0],2)]\\n\\n        model = BayesianRidge()\\n        model.fit(X_train, y_train)\\n        yhat = model.predict(X_test)\\n        mae = mean_absolute_error(y_test, yhat)\\n        y = model.predict(test)\\n        a+=1\\n        final_table.loc[a] = [\\'Bayesian Ridge Regression\\'] + [round(mae,2)] + [round(y[0],2)]\\n\\n        model =  SVR(C=1.0, epsilon=0.2)\\n        model.fit(X_train, y_train)\\n        yhat = model.predict(X_test)\\n        mae = mean_absolute_error(y_test, yhat)\\n        y = model.predict(test)\\n        a+=1\\n        final_table.loc[a] = [\\'Support Vector Regression\\'] + [round(mae,2)] + [round(y[0],2)]\\n\\n        model = KNeighborsRegressor(n_neighbors = 2)\\n        model.fit(X_train, y_train)\\n        yhat = model.predict(X_test)\\n        mae = mean_absolute_error(y_test, yhat)\\n        y = model.predict(test)\\n        a+=1\\n        final_table.loc[a] = [\\'KNN Regression\\'] + [round(mae,2)] + [round(y[0],2)]\\n        final_table.sort_values(\"Mae Score\", axis = 0, ascending = True, \\n                     inplace = True, na_position =\\'last\\') \\n        ff_table.loc[b] = [x] + [final_table.iloc[0,1]] + [final_table.iloc[0,0]]\\n        b += 1\\n        ff_table.sort_values(\"mae score\", axis = 0, ascending = True, \\n                         inplace = True, na_position =\\'last\\')    \\n        print(rs,\" \",round(x,2),\" \",ff_table.iloc[0,1],\" \",ff_table.iloc[0,2])\\n        x+=0.01\\n    rs+=1\\nfff_table.sort_values(\"mae score\", axis = 0, ascending = True, \\n                     inplace = True, na_position =\\'last\\') \\nfff_table.head(20)        \\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This code can almost take 15-20 minutes to check for the most optimum test size and the random state \n",
    "## to fit the model while efficiently decreasing the mae value as it takes the best in every iteration.\n",
    "\n",
    "\"\"\"\n",
    "from math import sqrt\n",
    "ff_table = pd.DataFrame(columns=['test size','mae score','model name'])\n",
    "fff_table = pd.DataFrame(columns=['random state', 'test size','mae score','model name'])\n",
    "b=0\n",
    "x=0.10\n",
    "rs= 1\n",
    "q=0\n",
    "while rs <=50:\n",
    "    x=0.10\n",
    "    while x <= 0.66:\n",
    "        dataframe = pd.read_csv(\"student_time_spent - student_scores.csv\")\n",
    "        data_values = dataframe.values\n",
    "        X, y = data_values[:, :-1], data_values[:, -1]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=round(x,2), random_state=rs)\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train) \n",
    "        yhat = model.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, yhat)\n",
    "        test = np.array([[9.25]])\n",
    "        y = model.predict(test)\n",
    "        final_table = pd.DataFrame(columns=['Model Name','Mae Score', 'Predicted Score for 9.25 hrs'])\n",
    "        a=0\n",
    "        final_table.loc[a] = ['Linear Regression Model'] + [round(mae,2)] + [round(y[0],2)]\n",
    "\n",
    "        model = RandomForestRegressor(random_state=1, n_estimators=32)\n",
    "        model.fit(X_train, y_train)\n",
    "        yhat = model.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, yhat)\n",
    "        y = model.predict(test)\n",
    "        a+=1\n",
    "        final_table.loc[a] = ['Random Forest Regression'] + [round(mae,2)] + [round(y[0],2)]\n",
    "\n",
    "        model = DecisionTreeRegressor(random_state=1)\n",
    "        model.fit(X_train, y_train)\n",
    "        yhat = model.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, yhat)\n",
    "        y = model.predict(test)\n",
    "        a+=1\n",
    "        final_table.loc[a] = ['Decision Tree Regression'] + [round(mae,2)] + [round(y[0],2)]\n",
    "\n",
    "        model =  GradientBoostingRegressor(random_state=1)\n",
    "        model.fit(X_train, y_train)\n",
    "        yhat = model.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, yhat)\n",
    "        y = model.predict(test)\n",
    "        a+=1\n",
    "        final_table.loc[a] = ['GB Regression Model'] + [round(mae,2)] + [round(y[0],2)]\n",
    "\n",
    "        model = regressor = xgb.XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        reg_lambda=1,\n",
    "        gamma=0,\n",
    "        max_depth=4\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        yhat = model.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, yhat)\n",
    "        y = model.predict(test)\n",
    "        a+=1\n",
    "        final_table.loc[a] = ['XGB Regression Model'] + [round(mae,2)] + [round(y[0],2)]\n",
    "\n",
    "        model = BayesianRidge()\n",
    "        model.fit(X_train, y_train)\n",
    "        yhat = model.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, yhat)\n",
    "        y = model.predict(test)\n",
    "        a+=1\n",
    "        final_table.loc[a] = ['Bayesian Ridge Regression'] + [round(mae,2)] + [round(y[0],2)]\n",
    "\n",
    "        model =  SVR(C=1.0, epsilon=0.2)\n",
    "        model.fit(X_train, y_train)\n",
    "        yhat = model.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, yhat)\n",
    "        y = model.predict(test)\n",
    "        a+=1\n",
    "        final_table.loc[a] = ['Support Vector Regression'] + [round(mae,2)] + [round(y[0],2)]\n",
    "\n",
    "        model = KNeighborsRegressor(n_neighbors = 2)\n",
    "        model.fit(X_train, y_train)\n",
    "        yhat = model.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, yhat)\n",
    "        y = model.predict(test)\n",
    "        a+=1\n",
    "        final_table.loc[a] = ['KNN Regression'] + [round(mae,2)] + [round(y[0],2)]\n",
    "        final_table.sort_values(\"Mae Score\", axis = 0, ascending = True, \n",
    "                     inplace = True, na_position ='last') \n",
    "        ff_table.loc[b] = [x] + [final_table.iloc[0,1]] + [final_table.iloc[0,0]]\n",
    "        b += 1\n",
    "        ff_table.sort_values(\"mae score\", axis = 0, ascending = True, \n",
    "                         inplace = True, na_position ='last')    \n",
    "        print(rs,\" \",round(x,2),\" \",ff_table.iloc[0,1],\" \",ff_table.iloc[0,2])\n",
    "        x+=0.01\n",
    "    rs+=1\n",
    "fff_table.sort_values(\"mae score\", axis = 0, ascending = True, \n",
    "                     inplace = True, na_position ='last') \n",
    "fff_table.head(20)        \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After Running the above code we can clearly see that that the most optipum value of mae is as follows:\n",
    "\n",
    "### 1)Test Size           =   0.12\n",
    "### 2)Random State  =   47\n",
    "### 3)Mae value         =   0.67\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model (KNN Regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE For Support Vector Regression: 0.667\n",
      "Predicted Score 91.5\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsRegressor(n_neighbors = 2)\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE For Support Vector Regression: %.3f' % mae)\n",
    "\n",
    "test = np.array([[9.25]])\n",
    "y = model.predict(test)\n",
    "print('Predicted Score',round(y[0],2))\n",
    "\n",
    "a+=1\n",
    "final_table.loc[a] = ['KNN Regression'] + [round(mae,2)] + [round(y[0],2)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
